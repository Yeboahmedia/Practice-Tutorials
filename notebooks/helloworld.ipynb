{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train simple data\n",
    "Load and prepare the MNIST dataset. The pixel values of the images range from 0 through 255. Scale these values to a range of 0 to 1 by dividing the values by 255.0. This also converts the sample data from integers to floating-point numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensonflow Version: 2.15.0\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 0.2961 - accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 487us/step - loss: 0.1415 - accuracy: 0.9574\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 463us/step - loss: 0.1051 - accuracy: 0.9682\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 0.0870 - accuracy: 0.9733\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 0.0745 - accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e9a92fd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('Tensonflow Version:', tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "## lets train the model using Sequetial Layers\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])\n",
    "\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "\n",
    "#convert logits to probabilities\n",
    "tf.nn.softmax(predictions).numpy\n",
    "\n",
    "\n",
    "# define a loss function\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "\n",
    "# Configure and compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train and evaluate model\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0762 - accuracy: 0.9756 - 95ms/epoch - 305us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07619474828243256, 0.975600004196167]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaulate the model\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.44948515e-08, 1.16440916e-07, 2.44766193e-06, 9.70573397e-04,\n",
       "        2.99518331e-13, 1.39713995e-06, 3.59301178e-14, 9.99024391e-01,\n",
       "        1.84469869e-07, 7.73091870e-07],\n",
       "       [5.61137938e-07, 1.08957747e-05, 9.99853134e-01, 1.31283392e-04,\n",
       "        3.44416505e-14, 1.13072906e-06, 2.00374242e-08, 1.70702956e-13,\n",
       "        2.99018666e-06, 3.39757562e-12],\n",
       "       [2.84400556e-07, 9.98994887e-01, 7.10137829e-05, 2.91890319e-05,\n",
       "        3.08000199e-05, 2.01517578e-05, 4.37096642e-05, 4.97319968e-04,\n",
       "        3.12524731e-04, 2.45790403e-07],\n",
       "       [9.99936223e-01, 2.75682677e-09, 7.10796439e-06, 1.42967622e-07,\n",
       "        2.12069970e-08, 4.61704185e-05, 3.40415727e-06, 3.47071887e-06,\n",
       "        3.11526840e-08, 3.37768870e-06],\n",
       "       [2.23019310e-06, 3.54022062e-10, 1.66151676e-06, 1.81648669e-08,\n",
       "        9.94597435e-01, 4.05264274e-07, 9.22775257e-07, 1.00630503e-04,\n",
       "        1.27162525e-06, 5.29544614e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
